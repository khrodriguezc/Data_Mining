{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "Klaus Hernando Rodr√≠guez Cruz - Cod: 201124457\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.038</td>\n",
       "      <td>33.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.40</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.059</td>\n",
       "      <td>44.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.22</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>44.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99578</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.041</td>\n",
       "      <td>40.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.056</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.99536</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4725            6.9             0.310         0.33            12.7      0.038   \n",
       "103             7.5             0.305         0.40            18.9      0.059   \n",
       "3027            7.4             0.320         0.22            11.7      0.035   \n",
       "2891            6.9             0.200         0.30             4.7      0.041   \n",
       "4020            6.4             0.370         0.12             5.9      0.056   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4725                 33.0                 116.0  0.99540  3.04       0.65   \n",
       "103                  44.0                 170.0  1.00000  2.99       0.46   \n",
       "3027                 44.0                 150.0  0.99578  3.10       0.45   \n",
       "2891                 40.0                 148.0  0.99320  3.16       0.35   \n",
       "4020                  6.0                  91.0  0.99536  3.06       0.46   \n",
       "\n",
       "      alcohol  quality   type  \n",
       "4725     10.4        6  white  \n",
       "103       9.0        5  white  \n",
       "3027     10.4        5  white  \n",
       "2891     10.2        6  white  \n",
       "4020      8.4        4  white  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>red</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>681.0</td>\n",
       "      <td>1457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>638.0</td>\n",
       "      <td>2198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199.0</td>\n",
       "      <td>880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type       red   white\n",
       "quality               \n",
       "3         10.0    20.0\n",
       "4         53.0   163.0\n",
       "5        681.0  1457.0\n",
       "6        638.0  2198.0\n",
       "7        199.0   880.0\n",
       "8         18.0   175.0\n",
       "9          NaN     5.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func =lambda x:x.count()\n",
    "pd.pivot_table(data, index='quality', columns='type', values= 'pH', aggfunc=func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Standarized the features (not the quality)\n",
    "* Create a binary target for each type of wine\n",
    "* Create two Linear SVM's for the white and red wines, repectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clasificaci√≥n de base por tipo de vino (Rojo & Blanco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarizaci√≥n de las caracter√≠sticas de los vinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality',\n",
       " 'type']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "sc.fit(data1)\n",
    "data_std= sc.transform(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16608919, -0.42318303,  0.28468605, ..., -1.35904886,\n",
       "        -0.54617826, -1.41855821],\n",
       "       [-0.70607349, -0.24094936,  0.14704613, ...,  0.50691489,\n",
       "        -0.27735097, -0.83161516],\n",
       "       [ 0.68245757, -0.36243847,  0.55996589, ...,  0.25811972,\n",
       "        -0.61338508, -0.32852111],\n",
       "       ...,\n",
       "       [-0.70607349,  1.03468634, -1.29817304, ...,  1.25330039,\n",
       "         1.47002637,  0.42611996],\n",
       "       [-1.01463595,  1.85473786, -1.366993  , ...,  2.18628226,\n",
       "         1.20119908, -0.2446721 ],\n",
       "       [-0.93749534, -0.1802048 ,  1.04170561, ...,  1.06670401,\n",
       "         0.86516498,  0.42611996]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_std=pd.DataFrame(np.array(data_std),columns=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data[['quality','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std=pd.concat([data1_std,data2],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datared = data_std[data_std['type']=='red']\n",
    "datawhite = data_std[data_std['type']=='white']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n del target por tipo de vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaus_000\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\klaus_000\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Taget para el vino blanco\n",
    "datawhite['quality2']=np.where(datawhite.quality>5,'good','bad')\n",
    "#Target para el vino rojo\n",
    "datared['quality2']=np.where(datared.quality>5,'good','bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_white= datawhite[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y_white= datawhite['quality2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partci√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_white_train,x_white_test,y_white_train, y_white_test= train_test_split(x_white,y_white,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm.fit(x_white_train,y_white_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.735374\n"
     ]
    }
   ],
   "source": [
    "y_white_pred=svm.predict(x_white_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino blanco\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_white_test,y_white_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Vinos Rojos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red= datared[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y_red= datared['quality2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partci√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_red_train,x_red_test,y_red_train, y_red_test= train_test_split(x_red,y_red,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_r = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm_r.fit(x_red_train,y_red_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.747917\n"
     ]
    }
   ],
   "source": [
    "y_red_pred=svm_r.predict(x_red_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino rojo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_red_test,y_red_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‚Äòpoly‚Äô, ‚Äòrbf‚Äô, ‚Äòsigmoid‚Äô)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM's Vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.723129\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'poly'\n",
    "svm.p_w = SVC(kernel='poly', C=1.0, random_state=0)\n",
    "svm.p_w.fit(x_white_train,y_white_train)\n",
    "y_white_pred_p=svm.p_w.predict(x_white_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino blanco\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_white_test,y_white_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.768707\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'rbf'\n",
    "svm.b_w = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm.b_w.fit(x_white_train,y_white_train)\n",
    "y_white_pred_b=svm.b_w.predict(x_white_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino blanco\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_white_test,y_white_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.666667\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'sigmoid'\n",
    "svm.s_w = SVC(kernel='sigmoid', C=1.0, random_state=0)\n",
    "svm.s_w.fit(x_white_train,y_white_train)\n",
    "y_white_pred_s=svm.s_w.predict(x_white_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino blanco\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_white_test,y_white_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del algoritmo de clasidicaci√≥n para el grupo de vinos blancos, el algoritmo que proporciona un mayor accuracy es el algoritmo de kernel 'rbf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM's Vino Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.735417\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'poly'\n",
    "svm.p_r = SVC(kernel='poly', C=1.0, random_state=0)\n",
    "svm.p_r.fit(x_red_train,y_red_train)\n",
    "y_red_pred_p=svm.p_r.predict(x_red_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino rojo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_red_test,y_red_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.731250\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'rbf'\n",
    "svm.b_r = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm.b_r.fit(x_red_train,y_red_train)\n",
    "y_red_pred_b=svm.b_r.predict(x_red_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino rojo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_red_test,y_red_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.618750\n"
     ]
    }
   ],
   "source": [
    "# Kernel 'sigmoid'\n",
    "svm.s_r = SVC(kernel='sigmoid', C=1.0, random_state=0)\n",
    "svm.s_r.fit(x_red_train,y_red_train)\n",
    "y_red_pred_s=svm.s_r.predict(x_red_test)\n",
    "#Test de Accuracy para el algoritmo SVM vino rojo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%2f'% accuracy_score(y_red_test,y_red_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del algoritmo de clasidicaci√≥n para el grupo de vinos rojos, el algoritmo que proporciona un mayor accuracy es el algoritmo de kernel 'linear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM Vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_white(c,g):\n",
    "    svm.b_w = SVC(kernel='rbf', gamma= g, C=c, random_state=0)\n",
    "    svm.b_w.fit(x_white_train,y_white_train)\n",
    "    y_white_pred_b=svm.b_w.predict(x_white_test)\n",
    "    #Test de Accuracy para el algoritmo SVM vino blanco\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return print('C= %f, gamma=%f,Accuracy:%2f'% (c,g, accuracy_score(y_white_test,y_white_pred_b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.100000, gamma=0.010000,Accuracy:0.655782\n",
      "C= 0.100000, gamma=0.001000,Accuracy:0.641497\n",
      "C= 0.100000, gamma=0.000100,Accuracy:0.641497\n",
      "C= 1.000000, gamma=0.010000,Accuracy:0.734014\n",
      "C= 1.000000, gamma=0.001000,Accuracy:0.657143\n",
      "C= 1.000000, gamma=0.000100,Accuracy:0.641497\n",
      "C= 10.000000, gamma=0.010000,Accuracy:0.751701\n",
      "C= 10.000000, gamma=0.001000,Accuracy:0.725850\n",
      "C= 10.000000, gamma=0.000100,Accuracy:0.657143\n",
      "C= 100.000000, gamma=0.010000,Accuracy:0.759864\n",
      "C= 100.000000, gamma=0.001000,Accuracy:0.744898\n",
      "C= 100.000000, gamma=0.000100,Accuracy:0.723810\n",
      "C= 1000.000000, gamma=0.010000,Accuracy:0.763946\n",
      "C= 1000.000000, gamma=0.001000,Accuracy:0.754422\n",
      "C= 1000.000000, gamma=0.000100,Accuracy:0.732653\n"
     ]
    }
   ],
   "source": [
    "SVM_white(0.1,0.01)\n",
    "SVM_white(0.1,0.001)\n",
    "SVM_white(0.1,0.0001)\n",
    "SVM_white(1,0.01)\n",
    "SVM_white(1,0.001)\n",
    "SVM_white(1,0.0001)\n",
    "SVM_white(10,0.01)\n",
    "SVM_white(10,0.001)\n",
    "SVM_white(10,0.0001)\n",
    "SVM_white(100,0.01)\n",
    "SVM_white(100,0.001)\n",
    "SVM_white(100,0.0001)\n",
    "SVM_white(1000,0.01)\n",
    "SVM_white(1000,0.001)\n",
    "SVM_white(1000,0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 1.000000, gamma=0.090000,Accuracy:0.768027\n"
     ]
    }
   ],
   "source": [
    "SVM_white(1,0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del modelo de clasificaci√≥n del vino blanco, el mejor accuracy se alcanza con el algoritmo SVM 'rbf'con los par√°metros C=1 y gamma=0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Vino Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_red(c,g):\n",
    "    svm_r = SVC(kernel='linear', gamma= g, C=c, random_state=0)\n",
    "    svm_r.fit(x_red_train,y_red_train)\n",
    "    y_red_pred=svm_r.predict(x_red_test)\n",
    "    #Test de Accuracy para el algoritmo SVM vino blanco\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return print('C= %f, gamma=%f,Accuracy:%2f'% (c,g, accuracy_score(y_red_test,y_red_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.100000, gamma=0.010000,Accuracy:0.752083\n",
      "C= 0.100000, gamma=0.001000,Accuracy:0.752083\n",
      "C= 0.100000, gamma=0.000100,Accuracy:0.752083\n",
      "C= 1.000000, gamma=0.010000,Accuracy:0.747917\n",
      "C= 1.000000, gamma=0.001000,Accuracy:0.747917\n",
      "C= 1.000000, gamma=0.000100,Accuracy:0.747917\n",
      "C= 10.000000, gamma=0.010000,Accuracy:0.750000\n",
      "C= 10.000000, gamma=0.001000,Accuracy:0.750000\n",
      "C= 10.000000, gamma=0.000100,Accuracy:0.750000\n",
      "C= 100.000000, gamma=0.010000,Accuracy:0.750000\n",
      "C= 100.000000, gamma=0.001000,Accuracy:0.750000\n",
      "C= 100.000000, gamma=0.000100,Accuracy:0.750000\n",
      "C= 1000.000000, gamma=0.010000,Accuracy:0.747917\n",
      "C= 1000.000000, gamma=0.001000,Accuracy:0.747917\n",
      "C= 1000.000000, gamma=0.000100,Accuracy:0.747917\n"
     ]
    }
   ],
   "source": [
    "SVM_red(0.1,0.01)\n",
    "SVM_red(0.1,0.001)\n",
    "SVM_red(0.1,0.0001)\n",
    "SVM_red(1,0.01)\n",
    "SVM_red(1,0.001)\n",
    "SVM_red(1,0.0001)\n",
    "SVM_red(10,0.01)\n",
    "SVM_red(10,0.001)\n",
    "SVM_red(10,0.0001)\n",
    "SVM_red(100,0.01)\n",
    "SVM_red(100,0.001)\n",
    "SVM_red(100,0.0001)\n",
    "SVM_red(1000,0.01)\n",
    "SVM_red(1000,0.001)\n",
    "SVM_red(1000,0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del modelo de clasificaci√≥n del vino rojo, el mejor accuracy se alcanza con el algoritmo SVM 'linear'con los par√°metros C=0.1 y gamma=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regresi√≥n Log√≠stica - Vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.739456\n"
     ]
    }
   ],
   "source": [
    "# Estimando un algoritmo de clasificaci√≥n v√≠a regresi√≥n Lineal\n",
    "from sklearn.linear_model import LogisticRegression #Importando la librer√≠a de regresi√≥n Lineal con Sklearn\n",
    "lr= LogisticRegression(solver='liblinear',C=1e9, random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "lr.fit(x_white_train,y_white_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train\n",
    "y_pred =lr.predict_proba(x_white_test) # Predicci√≥n de los valores para X_test\n",
    "import sklearn.metrics\n",
    "score = lr.score(x_white_test, y_white_test) # Otra forma de medir el accuracy de un modelo de regresi√≥n\n",
    "print('Accuracy:%2f'% score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del modelo de clasificaci√≥n del vino blanco, el mejor accuracy se alcanza con el algoritmo SVM 'rbf'con los par√°metros C=1 y gamma=0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n Log√≠stica - Vino Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.747917\n"
     ]
    }
   ],
   "source": [
    "# Estimando un algoritmo de clasificaci√≥n v√≠a regresi√≥n Lineal\n",
    "from sklearn.linear_model import LogisticRegression #Importando la librer√≠a de regresi√≥n Lineal con Sklearn\n",
    "lr= LogisticRegression(solver='liblinear',C=1e9, random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "lr.fit(x_red_train,y_red_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train\n",
    "y_pred =lr.predict_proba(x_red_test) # Predicci√≥n de los valores para X_test\n",
    "import sklearn.metrics\n",
    "score = lr.score(x_red_test, y_red_test) # Otra forma de medir el accuracy de un modelo de regresi√≥n\n",
    "print('Accuracy:%2f'% score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la clasificaci√≥n de vino rojo, el mejor algoritmo sigue siendo SVM 'linear'con los par√°metros C=0.1 y gamma=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n Lineal para Vino- Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_white=data_w[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y_white=data_w['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partci√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_white_train,x_white_test,y_white_train, y_white_test= train_test_split(x_white,y_white,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "sc.fit(x_white_train)\n",
    "x_tr_white_std= sc.transform(x_white_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean, y_std = y_white_train.mean(), y_white_train.std()\n",
    "y_tr_white_std = (y_white_train - y_mean)/ y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10963305, -0.20719608, -0.00203301,  0.54931424, -0.01065429,\n",
       "        0.09917651, -0.01159626, -0.6728308 ,  0.14996364,  0.08709927,\n",
       "        0.18008521])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimaci√≥n del modelo usando OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "linreg.fit(x_tr_white_std, y_tr_white_std)\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "sc.fit(x_white_train)\n",
    "x_tst_white_std= sc.transform(x_white_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_white_std = (y_white_test - y_mean)/ y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE metodolog√≠a OLS: 0.786956309844809\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = linreg.predict(x_tst_white_std)\n",
    "# Calculo MSE Metodolog√≠a OLS\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MSE metodolog√≠a OLS:', metrics.mean_squared_error(y_tst_white_std, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0054846 , -0.21362165,  0.00431453,  0.2769652 , -0.01165198,\n",
       "        0.11299672, -0.02896232, -0.22637824,  0.05790943,  0.07240937,\n",
       "        0.39374484])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimaci√≥n del modelo usando SDG\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "linreg_SDG = SGDRegressor(fit_intercept=False, max_iter=500,tol = 0.0000001)\n",
    "linreg_SDG.fit(x_tr_white_std, y_tr_white_std)\n",
    "linreg_SDG.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE metodolog√≠a SDG: 0.7804579897023612\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = linreg_SDG.predict(x_tst_white_std)\n",
    "# Calculo MSE Metodolog√≠a OLS\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MSE metodolog√≠a SDG:', metrics.mean_squared_error(y_tst_white_std, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n Lineal para Vino- Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red=data_r[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y_red=data_r['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partci√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_red_train,x_red_test,y_red_train, y_red_test= train_test_split(x_red,y_red,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "sc.fit(x_red_train)\n",
    "x_tr_red_std= sc.transform(x_red_train)\n",
    "y_mean, y_std = y_red_train.mean(), y_red_train.std()\n",
    "y_tr_red_std = (y_red_train - y_mean)/ y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04278913, -0.27324555, -0.02329091,  0.04009502, -0.11420775,\n",
       "        0.02601282, -0.12493469, -0.03856832, -0.07488928,  0.18532489,\n",
       "        0.34575834])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimaci√≥n del modelo usando OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "linreg.fit(x_tr_red_std, y_tr_red_std)\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "sc.fit(x_red_train)\n",
    "x_tst_red_std= sc.transform(x_red_test)\n",
    "y_tst_red_std = (y_red_test - y_mean)/ y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE metodolog√≠a OLS: 0.5910660686504577\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = linreg.predict(x_tst_red_std)\n",
    "# Calculo MSE Metodolog√≠a OLS\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MSE metodolog√≠a OLS:', metrics.mean_squared_error(y_tst_red_std, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07025671, -0.26376978, -0.01270404,  0.05992728, -0.12226253,\n",
       "        0.01506832, -0.13533236, -0.0578797 , -0.06301727,  0.17203292,\n",
       "        0.33446791])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimaci√≥n del modelo usando SDG\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "linreg_SDG = SGDRegressor(fit_intercept=False, max_iter=500,tol = 0.0000001)\n",
    "linreg_SDG.fit(x_tr_red_std, y_tr_red_std)\n",
    "linreg_SDG.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE metodolog√≠a SDG: 0.5958737769598367\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = linreg_SDG.predict(x_tst_red_std)\n",
    "# Calculo MSE Metodolog√≠a OLS\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MSE metodolog√≠a SDG:', metrics.mean_squared_error(y_tst_red_std, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression- Vino Blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Ridge Regression alpha 0.1: 0.7797233024279019\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1 \n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg1 = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg1.fit(x_white_train, y_white_train)\n",
    "y_pred1 = ridgereg1.predict(x_white_test)\n",
    "print('MSE Ridge Regression alpha 0.1:',np.sqrt(metrics.mean_squared_error(y_white_test, y_pred1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Ridge Regression alpha 1: 0.8120347448335605\n"
     ]
    }
   ],
   "source": [
    "# alpha=1 \n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg2 = Ridge(alpha=1, normalize=True)\n",
    "ridgereg2.fit(x_white_train, y_white_train)\n",
    "y_pred2 = ridgereg2.predict(x_white_test)\n",
    "print('MSE Ridge Regression alpha 1:',np.sqrt(metrics.mean_squared_error(y_white_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.48885792e-03 -1.63467861e+00  9.50634401e-03  3.42636009e-02\n",
      " -1.75610555e+00  5.50671129e-03 -8.39582620e-04 -5.13078081e+01\n",
      "  3.09478498e-01  4.17468570e-01  2.52495787e-01]\n"
     ]
    }
   ],
   "source": [
    "print(ridgereg1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.72539154e-02 -8.57988875e-01  5.04142556e-02  6.03593151e-03\n",
      " -2.45762035e+00  2.73257813e-03 -7.31960665e-04 -2.58883533e+01\n",
      "  1.61366105e-01  2.21480222e-01  1.28845959e-01]\n"
     ]
    }
   ],
   "source": [
    "print(ridgereg2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los coeficientes obtenidos para el modelo de regresi√≥n Lineal y el modelo de regresi√≥n Ridge se tienen que todos los coeficientes son menores para el caso de la regresi√≥n ridge debido a la restricci√≥n adicional incluida en el proceso de optimizaci√≥n.\n",
    "Adicionalmente el accuracy del modelo de regresi√≥n ridge con alpha=1 es mayor que el accuracy obtenido con la estimaci√≥n del modelo lineal v√≠a OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression- Vino Rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Ridge Regression alpha 0.1: 0.6344194631893536\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1 \n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg1 = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg1.fit(x_red_train, y_red_train)\n",
    "y_pred1 = ridgereg1.predict(x_red_test)\n",
    "print('MSE Ridge Regression alpha 0.1:',np.sqrt(metrics.mean_squared_error(y_red_test, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Ridge Regression alpha 0.1: 0.6569663486954709\n"
     ]
    }
   ],
   "source": [
    "# alpha=1 \n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg2 = Ridge(alpha=1, normalize=True)\n",
    "ridgereg2.fit(x_red_train, y_red_train)\n",
    "y_pred2 = ridgereg2.predict(x_red_test)\n",
    "print('MSE Ridge Regression alpha 0.1:',np.sqrt(metrics.mean_squared_error(y_red_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.68276389e-02 -1.08428984e+00  5.65341014e-02  2.36543153e-02\n",
      " -1.76994118e+00  1.12334507e-03 -2.71388369e-03 -3.00009155e+01\n",
      " -2.54181268e-01  7.95554880e-01  2.33458671e-01]\n"
     ]
    }
   ],
   "source": [
    "print(ridgereg1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.83712556e-02 -6.75208907e-01  2.49195784e-01  1.00770556e-02\n",
      " -1.01625393e+00 -8.36569442e-04 -1.63673406e-03 -2.68060154e+01\n",
      " -1.00168476e-01  4.58489960e-01  1.41011129e-01]\n"
     ]
    }
   ],
   "source": [
    "print(ridgereg2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los coeficientes obtenidos para el modelo de regresi√≥n Lineal y el modelo de regresi√≥n Ridge se tienen que todos los coeficientes son menores para el caso de la regresi√≥n ridge debido a la restricci√≥n adicional incluida en el proceso de optimizaci√≥n.\n",
    "Adicionalmente el accuracy del modelo de regresi√≥n ridge con alpha=1 es mayor que el accuracy obtenido con la estimaci√≥n del modelo lineal v√≠a OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y=data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partici√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train, y_test= train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Lasso Regression alpha 0.001: 0.7536931857261449\n",
      "N√∫mero de variables usadas:3\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression alpha=0.01\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg1 = Lasso(alpha=0.001, normalize=True, max_iter=100000000)\n",
    "lassoreg1.fit(x_train, y_train)\n",
    "# calculate RMSE (for alpha=0.001)\n",
    "y_pred1 = lassoreg1.predict(x_test)\n",
    "print('MSE Lasso Regression alpha 0.001:',np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))\n",
    "print(\"N√∫mero de variables usadas:{}\".format(np.sum(lassoreg1.coef_!=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Lasso Regression alpha 0.1: 0.866069106529371\n",
      "N√∫mero de variables usadas:0\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression alpha=0.1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg2 = Lasso(alpha=0.1, normalize=True, max_iter=100000000)\n",
    "lassoreg2.fit(x_train, y_train)\n",
    "# calculate RMSE (for alpha=0.01)\n",
    "y_pred2 = lassoreg2.predict(x_test)\n",
    "print('MSE Lasso Regression alpha 0.1:',np.sqrt(metrics.mean_squared_error(y_test, y_pred2)))\n",
    "print(\"N√∫mero de variables usadas:{}\".format(np.sum(lassoreg2.coef_!=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Lasso Regression alpha 1: 0.866069106529371\n",
      "N√∫mero de variables usadas:0\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression alpha=1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg3 = Lasso(alpha=1, normalize=True, max_iter=100000000)\n",
    "lassoreg3.fit(x_train, y_train)\n",
    "# calculate RMSE (for alpha=1)\n",
    "y_pred3 = lassoreg3.predict(x_test)\n",
    "print('MSE Lasso Regression alpha 1:',np.sqrt(metrics.mean_squared_error(y_test, y_pred3)))\n",
    "print(\"N√∫mero de variables usadas:{}\".format(np.sum(lassoreg3.coef_!=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.920000e-03 -1.812410e+00 -0.000000e+00  5.132000e-02 -8.706700e-01\n",
      "  4.910000e-03 -3.000000e-04 -8.206488e+01  3.893200e-01  4.415200e-01\n",
      "  2.594200e-01]\n"
     ]
    }
   ],
   "source": [
    " print(np.around(lassoreg1.coef_,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0. -0. -0. -0.  0. -0. -0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    " print(np.around(lassoreg3.coef_,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0. -0. -0. -0.  0. -0. -0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    " print(np.around(lassoreg3.coef_,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taget para el vino blanco\n",
    "data['quality2']=np.where(data.quality>6,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n",
    " 'density','pH','sulphates','alcohol']]\n",
    "y= data['quality2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partci√≥n de la muesta en train (70%) y Test (30%) \n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train, y_test= train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizaci√≥n de la base x\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler() #definici√≥n de la funci√≥n de estandarizaci√≥n\n",
    "sc.fit(x_train) # defino con que media y varianza se ajustara los datos\n",
    "x_train_std = sc.transform(x_train) # Definici√≥n de la variable estandarizada\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #Importando la librer√≠a de regresi√≥n Lineal con Sklearn\n",
    "lr= LogisticRegression(solver='liblinear',C=1e9, random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "lr.fit(x_train_std,y_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6045442, -0.5517844, -0.0600713,  0.8471515, -0.1801041,\n",
       "         0.2545709, -0.339323 , -0.8737092,  0.3902161,  0.3530193,\n",
       "         0.7605953]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3668430335097002"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =lr.predict(x_test_std)\n",
    "from sklearn.metrics import f1_score\n",
    "sklearn.metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci√≥n f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_ridge(c):\n",
    "    lr_ridge= LogisticRegression(solver='liblinear',C=c,penalty='l2',random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "    lr_ridge.fit(x_train_std,y_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train_std\n",
    "    y_pred =lr_ridge.predict(x_test_std)\n",
    "    from sklearn.metrics import f1_score\n",
    "    return print('C= %f, penalty=L2,f1 test:%2f'% (c, sklearn.metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.010000, penalty=L2,f1 test:0.346225\n",
      "C= 0.100000, penalty=L2,f1 test:0.363636\n",
      "C= 1.000000, penalty=L2,f1 test:0.366843\n"
     ]
    }
   ],
   "source": [
    "lr_ridge(0.01)\n",
    "lr_ridge(0.1)\n",
    "lr_ridge(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lasso(c):\n",
    "    lr_lasso= LogisticRegression(solver='liblinear',C=c,penalty='l1',random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "    lr_lasso.fit(x_train_std,y_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train_std\n",
    "    y_pred =lr_lasso.predict(x_test_std)\n",
    "    from sklearn.metrics import f1_score\n",
    "    return print('C= %f, penalty=L1,f1 test:%2f'% (c, sklearn.metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.010000, penalty=L1,f1 test:0.285714\n",
      "C= 0.100000, penalty=L1,f1 test:0.362657\n",
      "C= 1.000000, penalty=L1,f1 test:0.363958\n"
     ]
    }
   ],
   "source": [
    "lr_lasso(0.01)\n",
    "lr_lasso(0.1)\n",
    "lr_lasso(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci√≥n Coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_ridge_coef(c):\n",
    "    lr_ridge= LogisticRegression(solver='liblinear',C=c,penalty='l2',random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "    lr_ridge.fit(x_train_std,y_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train_std  \n",
    "    return print(lr_ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1652191 -0.322609   0.0286169  0.2679218 -0.1687948  0.1516568\n",
      "  -0.1658983 -0.2581105  0.1273893  0.2073783  0.7025499]]\n"
     ]
    }
   ],
   "source": [
    "lr_ridge_coef(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4365231 -0.5228868 -0.0388122  0.6267583 -0.2102074  0.2363162\n",
      "  -0.2933516 -0.5773121  0.2914872  0.3084422  0.8289398]]\n"
     ]
    }
   ],
   "source": [
    "lr_ridge_coef(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5787133 -0.5500858 -0.057581   0.8131656 -0.1863789  0.252602\n",
      "  -0.3331946 -0.8251086  0.37509    0.3464812  0.7747421]]\n"
     ]
    }
   ],
   "source": [
    "lr_ridge_coef(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lasso_coef(c):\n",
    "    lr_lasso= LogisticRegression(solver='liblinear',C=c,penalty='l1',random_state=0)# Definiendo la funci√≥n \"Lr\" con sus par√°metros\n",
    "    lr_lasso.fit(x_train_std,y_train) #Entrenando un algoritmo de Machine Learnig con el dataset x_train_std  \n",
    "    return print(lr_lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        -0.247048   0.         0.         0.         0.\n",
      "   0.         0.         0.         0.015347   0.8012157]]\n"
     ]
    }
   ],
   "source": [
    "lr_lasso_coef(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2692553 -0.5301376  0.         0.4313487 -0.1981116  0.1959009\n",
      "  -0.2184767 -0.2958936  0.1961613  0.2661656  0.9511966]]\n"
     ]
    }
   ],
   "source": [
    "lr_lasso_coef(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5677362 -0.5494197 -0.0533869  0.8018003 -0.1827472  0.2483202\n",
      "  -0.3264602 -0.8094252  0.3690874  0.3435417  0.7817504]]\n"
     ]
    }
   ],
   "source": [
    "lr_lasso_coef(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso el mejor f1 score es proporcionado por una regresi√≥n log√≠stica combinada con el algoritmo ridge con un valor de c=1, para los datos analizados los coeficientes son menores en todos los casos para las estimaciones realizadas bajo la metodolog√≠a lasso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
