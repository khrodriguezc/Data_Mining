{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarización de la base x\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler() #definición de la función de estandarización\n",
    "sc.fit(X_train) # defino con que media y varianza se ajustara los datos\n",
    "x_train_std = sc.transform(X_train) # Definición de la variable estandarizada\n",
    "x_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regresion:\n",
    "from sklearn.linear_model import LogisticRegression #Importando la librería de regresión Lineal con Sklearn\n",
    "lr= LogisticRegression(solver='liblinear',C=1e9, random_state=1)# Definiendo la función \"Lr\" con sus parámetros\n",
    "lr.fit(x_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.632373\n",
      "Accuracy test:0.642667\n"
     ]
    }
   ],
   "source": [
    "y_pred =lr.predict(x_test_std) # Predicción de los valores para X_test\n",
    "from sklearn import metrics\n",
    "print('f1 test:%2f'%metrics.f1_score(y_pred, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=None, random_state=123)\n",
    "treeclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.542800\n",
      "Accuracy test:0.540667\n"
     ]
    }
   ],
   "source": [
    "y_pred1 =treeclf.predict(X_test) # Predicción de los valores para X_test\n",
    "from sklearn import metrics\n",
    "print('f1 test:%2f'%metrics.f1_score(y_pred1, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct BaggingClassifier to use DecisionClassifier as the \"base estimator, Max_depth=None\"\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=None, random_state=123), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagreg1.fit(X_train, y_train)\n",
    "y_pred1 = bagreg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.635753\n",
      "Accuracy test:0.638667\n"
     ]
    }
   ],
   "source": [
    "print('f1 test:%2f'%metrics.f1_score(y_pred1, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct BaggingClassifier to use DecisionClassifier as the \"base estimator, Max_depth=2\"\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg2 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, random_state=123), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.643478\n",
      "Accuracy test:0.644667\n"
     ]
    }
   ],
   "source": [
    "bagreg2.fit(X_train, y_train)\n",
    "y_pred2 = bagreg2.predict(X_test)\n",
    "print('f1 test:%2f'%metrics.f1_score(y_pred2, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct Logit Classifier to use DecisionClassifier as the \"base estimator, \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg3 = BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear',C=1e9, random_state=1), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.631001\n",
      "Accuracy test:0.641333\n"
     ]
    }
   ],
   "source": [
    "bagreg3.fit(x_train_std, y_train)\n",
    "y_pred3 = bagreg3.predict(x_test_std)\n",
    "print('f1 test:%2f'%metrics.f1_score(y_pred3, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred3, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', BaggingClassifier(base_estimator=LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbos... n_estimators=100, n_jobs=1, oob_score=True,\n",
       "         random_state=1, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[('lr', bagreg3), ('dt2', bagreg2), ('dtn', bagreg1)],voting='hard')\n",
    "voting_clf.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = voting_clf.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.644159\n",
      "Accuracy test:0.648667\n"
     ]
    }
   ],
   "source": [
    "print('f1 test:%2f'%metrics.f1_score(y_pred4, y_test)) \n",
    "print('Accuracy test:%2f'% metrics.accuracy_score(y_pred4, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct BaggingClassifier to use DecisionClassifier as the \"base estimator, Max_depth=None\"\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=None, random_state=123), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagreg1.fit(X_train, y_train)\n",
    "y_pred1 = bagreg1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.83],\n",
       "       [0.35, 0.65],\n",
       "       [0.46, 0.54],\n",
       "       ...,\n",
       "       [0.45, 0.55],\n",
       "       [0.53, 0.47],\n",
       "       [0.66, 0.34]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: MatplotlibDeprecationWarning: numpy.arange\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.000000 0.6702127659574468\n",
      "Accuracy test:0.000000 0.504\n",
      "f1 test:0.100000 0.6729138777331549\n",
      "Accuracy test:0.100000 0.5113333333333333\n",
      "f1 test:0.200000 0.6866635902168897\n",
      "Accuracy test:0.200000 0.5473333333333333\n",
      "f1 test:0.300000 0.700246913580247\n",
      "Accuracy test:0.300000 0.5953333333333334\n",
      "f1 test:0.400000 0.6956521739130435\n",
      "Accuracy test:0.400000 0.6266666666666667\n",
      "f1 test:0.500000 0.6359447004608294\n",
      "Accuracy test:0.500000 0.6313333333333333\n",
      "f1 test:0.600000 0.5206402695871946\n",
      "Accuracy test:0.600000 0.6206666666666667\n",
      "f1 test:0.700000 0.3267429760665973\n",
      "Accuracy test:0.700000 0.5686666666666667\n",
      "f1 test:0.800000 0.1234866828087167\n",
      "Accuracy test:0.800000 0.5173333333333333\n",
      "f1 test:0.900000 0.015706806282722512\n",
      "Accuracy test:0.900000 0.49866666666666665\n",
      "f1 test:1.000000 0.0\n",
      "Accuracy test:1.000000 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pylab as pl\n",
    "probabilidad= pl.frange(0.0,1,0.1)\n",
    "for i in probabilidad:\n",
    "    y_pred1 = (bagreg1.predict_proba(X_test)[:,1]>=i).astype(bool)\n",
    "    y_pred_dt1=np.where(y_pred1==True,1,0)\n",
    "    print('f1 test:%2f'% i,metrics.f1_score(y_pred1, y_test)) \n",
    "    print('Accuracy test:%2f'% i,metrics.accuracy_score(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29674311, 0.70325689],\n",
       "       [0.36550694, 0.63449306],\n",
       "       [0.36212404, 0.63787596],\n",
       "       ...,\n",
       "       [0.32010389, 0.67989611],\n",
       "       [0.59688154, 0.40311846],\n",
       "       [0.68177572, 0.31822428]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción Probabilidad Modelo 2 : Decisiontree Max_Depth=2 \n",
    "y_pred2 = bagreg2.predict_proba(X_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: MatplotlibDeprecationWarning: numpy.arange\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.000000 0.6702127659574468\n",
      "Accuracy test:0.000000 0.504\n",
      "f1 test:0.100000 0.6702127659574468\n",
      "Accuracy test:0.100000 0.504\n",
      "f1 test:0.200000 0.6702127659574468\n",
      "Accuracy test:0.200000 0.504\n",
      "f1 test:0.300000 0.675336322869955\n",
      "Accuracy test:0.300000 0.5173333333333333\n",
      "f1 test:0.400000 0.702176403207331\n",
      "Accuracy test:0.400000 0.6533333333333333\n",
      "f1 test:0.500000 0.6434782608695653\n",
      "Accuracy test:0.500000 0.6446666666666667\n",
      "f1 test:0.600000 0.5701078582434514\n",
      "Accuracy test:0.600000 0.628\n",
      "f1 test:0.700000 0.180327868852459\n",
      "Accuracy test:0.700000 0.5333333333333333\n",
      "f1 test:0.800000 0.0\n",
      "Accuracy test:0.800000 0.496\n",
      "f1 test:0.900000 0.0\n",
      "Accuracy test:0.900000 0.496\n",
      "f1 test:1.000000 0.0\n",
      "Accuracy test:1.000000 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "y_pred2 = (bagreg2.predict_proba(X_test)[:,1]>=0.4).astype(bool)\n",
    "y_pred_dt2=np.where(y_pred2==True,1,0)\n",
    "import pylab as pl\n",
    "probabilidad= pl.frange(0.0,1,0.1)\n",
    "for i in probabilidad:\n",
    "    y_pred2 = (bagreg2.predict_proba(X_test)[:,1]>=i).astype(bool)\n",
    "    y_pred_dt2=np.where(y_pred2==True,1,0)\n",
    "    print('f1 test:%2f'% i,metrics.f1_score(y_pred2, y_test)) \n",
    "    print('Accuracy test:%2f'% i,metrics.accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34225656, 0.65774344],\n",
       "       [0.34943375, 0.65056625],\n",
       "       [0.36427564, 0.63572436],\n",
       "       ...,\n",
       "       [0.43129733, 0.56870267],\n",
       "       [0.73789391, 0.26210609],\n",
       "       [0.68886952, 0.31113048]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instruct Logit Classifier to use DecisionClassifier as the \"base estimator, \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg3 = BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear',C=1e9, random_state=1), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagreg3.fit(x_train_std, y_train)\n",
    "# Predicción Probabilidad Modelo 3 : Regresión Lineal\n",
    "y_pred3 = bagreg3.predict_proba(x_test_std)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: MatplotlibDeprecationWarning: numpy.arange\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 test:0.000000 0.6702127659574468\n",
      "Accuracy test:0.000000 0.504\n",
      "f1 test:0.100000 0.6702127659574468\n",
      "Accuracy test:0.100000 0.504\n",
      "f1 test:0.200000 0.6811397557666216\n",
      "Accuracy test:0.200000 0.53\n",
      "f1 test:0.300000 0.6977205153617442\n",
      "Accuracy test:0.300000 0.5933333333333334\n",
      "f1 test:0.400000 0.7029192902117917\n",
      "Accuracy test:0.400000 0.654\n",
      "f1 test:0.500000 0.6310013717421126\n",
      "Accuracy test:0.500000 0.6413333333333333\n",
      "f1 test:0.600000 0.5172124265323258\n",
      "Accuracy test:0.600000 0.6166666666666667\n",
      "f1 test:0.700000 0.35294117647058826\n",
      "Accuracy test:0.700000 0.582\n",
      "f1 test:0.800000 0.13349514563106793\n",
      "Accuracy test:0.800000 0.524\n",
      "f1 test:0.900000 0.025940337224383915\n",
      "Accuracy test:0.900000 0.49933333333333335\n",
      "f1 test:1.000000 0.0\n",
      "Accuracy test:1.000000 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0685215\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Maximización de F1- Scor modelo Logit\n",
    "import numpy as np \n",
    "import pylab as pl\n",
    "probabilidad= pl.frange(0.0,1,0.1)\n",
    "for i in probabilidad:\n",
    "    y_pred3 = (bagreg3.predict_proba(x_test_std)[:,1]>=i).astype(bool)\n",
    "    y_pred_lr=np.where(y_pred3==True,1,0)\n",
    "    print('f1 test:%2f'% i,metrics.f1_score(y_pred3, y_test)) \n",
    "    print('Accuracy test:%2f'% i,metrics.accuracy_score(y_pred3, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad que maximiza el modelo de clasificación Logit es 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', BaggingClassifier(base_estimator=LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbos... n_estimators=100, n_jobs=1, oob_score=True,\n",
       "         random_state=1, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[('lr', bagreg3), ('dt2', bagreg2), ('dtn', bagreg1)],voting='hard')\n",
    "voting_clf.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0e46c0d8e70b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred_all_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'n_estimators'"
     ]
    }
   ],
   "source": [
    "errors = np.zeros(voting_clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], voting_clf.n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "    oob_sample = ~clf.estimators_samples_[i]\n",
    "    y_pred_ = clf.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
